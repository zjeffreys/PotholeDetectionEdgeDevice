{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f56744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../services.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../services.py\n",
    "#!/usr/local/bin/python \n",
    "\n",
    "#*** DO NOT EDIT - GENERATED FROM services.ipynb ****\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from  mangorest.mango import webapi\n",
    "\n",
    "#*** new stuff for running inference ***\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import os # don't need this\n",
    "import numpy as np\n",
    "from django.http import HttpResponse\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "from django.http import JsonResponse\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# Checks queue for images\n",
    "@webapi(\"/app1/getPotholeQueue\")\n",
    "def view_pothole_queue(request,  **kwargs):\n",
    "    # Directory containing the files to parse\n",
    "    directory = \"PotholeQueue\"\n",
    "\n",
    "    # List to hold parsed data for each file\n",
    "    data_list = []\n",
    "    \n",
    "    # Loop over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file has a .jpg or .png extension\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Extract latitude, longitude, and datetime from the filename using a regular expression\n",
    "            match = re.match(r\"seattle:(?P<latitude>-?\\d+\\.\\d+)_(?P<longitude>-?\\d+\\.\\d+)_(?P<datetime>\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2})\\.(jpg|png)\", filename)\n",
    "            if match:\n",
    "                # Create a dictionary with the extracted values\n",
    "                data = {\n",
    "                    \"latitude\": float(match.group(\"latitude\")),\n",
    "                    \"longitude\": float(match.group(\"longitude\")),\n",
    "                    \"datetime\": match.group(\"datetime\"),\n",
    "                    \"image_type\": match.group(4) # Add the image file type to the dictionary\n",
    "                }\n",
    "                \n",
    "                # Read the image file and encode it in base64 format\n",
    "                with open(os.path.join(directory, filename), \"rb\") as image_file:\n",
    "                    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "                \n",
    "                # Add the base64-encoded image to the dictionary\n",
    "                data[\"image\"] = encoded_image\n",
    "                \n",
    "                # Add the dictionary to the list of parsed data\n",
    "                data_list.append(data)\n",
    "            else:\n",
    "                print(f\"Invalid filename format for file {filename}.\")\n",
    "        else:\n",
    "            print(f\"File {filename} is not a supported image file type.\")\n",
    "    \n",
    "    # Return the list of parsed data as a JSON string\n",
    "    return json.dumps(data_list)\n",
    "\n",
    "# Inferene Handeler\n",
    "def run_inference(image, model):\n",
    "    # Set output file path\n",
    "    output_file = os.path.join(\"..\", \"dynamic\", os.path.basename(image))\n",
    "    # Check if output file exists and delete it if it does\n",
    "    if os.path.isfile(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    # Load model and image, perform inference, and add labels\n",
    "    model_final = tf.keras.models.load_model(model)\n",
    "    img = cv2.imread(image)\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    imout = img.copy()\n",
    "    for e,result in enumerate(ssresults):\n",
    "        if e < 200:\n",
    "            x,y,w,h = result\n",
    "            timage = imout[y:y+h,x:x+w]\n",
    "            resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "            img = np.expand_dims(resized, axis=0)\n",
    "            out= model_final.predict(img)\n",
    "            if out[0][0] > 0.60:\n",
    "                # Add Labels & Design To Rectangles \n",
    "                label = \"Pothole: \" + str(round(out[0][0], 2))\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                thickness = 2\n",
    "                color = (255, 0, 0)\n",
    "                text_size, _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                text_x = x + w // 2 - text_size[0] // 2\n",
    "                text_y = y - text_size[1] - 5\n",
    "                cv2.putText(imout, label, (text_x, text_y), font, font_scale, color, thickness)\n",
    "                cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Save output image to output_file\n",
    "    cv2.imwrite(output_file, imout)\n",
    "    print(f\"Saving output image to {output_file}\")\n",
    "    \n",
    "    # Return the file location\n",
    "    return output_file\n",
    "    \n",
    "    # Return the file location\n",
    "    return output_file\n",
    "    ''' #OLD CODE\n",
    "    image_exists = os.path.isfile(image)\n",
    "    model_exists = os.path.isfile(model)\n",
    "    print(f\"\\nrun_inference(image={image} ({image_exists}), model={model} ({model_exists}))\\n\")\n",
    "    \n",
    "    # Set output file path\n",
    "    output_file = os.path.join(\"..\", \"dynamic\", \"output.png\")\n",
    "    # Check if output file exists and delete it if it does\n",
    "    if os.path.isfile(output_file):\n",
    "        os.remove(output_file)\n",
    "    \n",
    "    # Load model and image, perform inference, and add labels\n",
    "    model_final = tf.keras.models.load_model(model)\n",
    "    img = cv2.imread(image)\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    ssresults = ss.process()\n",
    "    imout = img.copy()\n",
    "    for e,result in enumerate(ssresults):\n",
    "        if e < 500:\n",
    "            x,y,w,h = result\n",
    "            timage = imout[y:y+h,x:x+w]\n",
    "            resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "            img = np.expand_dims(resized, axis=0)\n",
    "            out= model_final.predict(img)\n",
    "            if out[0][0] > 0.60:\n",
    "                # Add Labels & Design To Rectangles \n",
    "                label = \"Pothole: \" + str(round(out[0][0], 2))\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                thickness = 2\n",
    "                color = (255, 0, 0)\n",
    "                text_size, _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "                text_x = x + w // 2 - text_size[0] // 2\n",
    "                text_y = y - text_size[1] - 5\n",
    "                cv2.putText(imout, label, (text_x, text_y), font, font_scale, color, thickness)\n",
    "                cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Save output image to output_file\n",
    "    cv2.imwrite(output_file, imout)\n",
    "    print(f\"Saving output image to {output_file}\")\n",
    "    \n",
    "    # Return the file location\n",
    "    return output_file\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/app1/test\")\n",
    "def test( request,  **kwargs):\n",
    "    return \"APP 1 TEST version 1.0\"\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/app1/uploadfile\")\n",
    "def uploadfile( request,  **kwargs):\n",
    "    par = dict(request.GET)\n",
    "    par.update(request.POST)\n",
    "   # DESTDIR =\"/tmp/MYAPP/\" \n",
    "    DESTDIR = os.path.join(\"..\", \"dynamic\")\n",
    "\n",
    "    os.makedirs(DESTDIR, exist_ok=True)  # Create the destination directory if it does not exist\n",
    "\n",
    "    ret = \"\"\n",
    "    for file_ in request.FILES.getlist('file'):\n",
    "        filename = str(file_)\n",
    "        content = file_.read()\n",
    "        file_path = os.path.join(DESTDIR, str(file_))\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        ret += filename\n",
    "        if os.path.isfile(file_path):  # Check if the file exists in the destination directory\n",
    "            print(\" saved successfully.\")\n",
    "        else:\n",
    "            print(\"error uploading file\")\n",
    "    return ret\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "@webapi(\"/app1/processall\")\n",
    "def processfiles(request, **kwargs):\n",
    "    # Directory containing the files to parse\n",
    "    directory = \"PotholeQueue\"\n",
    "\n",
    "    # List to hold parsed data for each file\n",
    "    data_list = []\n",
    "\n",
    "    # Loop over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file has a .jpg or .png extension\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Extract latitude, longitude, and datetime from the filename using a regular expression\n",
    "            match = re.match(r\"seattle:(?P<latitude>-?\\d+\\.\\d+)_(?P<longitude>-?\\d+\\.\\d+)_(?P<datetime>\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2})\\.(jpg|png)\", filename)\n",
    "            if match:\n",
    "                # Create a dictionary with the extracted values\n",
    "                data = {\n",
    "                    \"latitude\": float(match.group(\"latitude\")),\n",
    "                    \"longitude\": float(match.group(\"longitude\")),\n",
    "                    \"datetime\": match.group(\"datetime\"),\n",
    "                    \"image_type\": match.group(4) # Add the image file type to the dictionary\n",
    "                }\n",
    "                \n",
    "                # Get the full path of the image file\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                \n",
    "                # Call the run_inference function to generate a new image\n",
    "                VGG = os.path.join('app1', 'Models/VGG.h5')\n",
    "                new_image_path = run_inference(image_path, VGG)\n",
    "                \n",
    "                # Read the new image file and encode it in base64 format\n",
    "                with open(new_image_path, \"rb\") as image_file:\n",
    "                    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "                \n",
    "                # Add the base64-encoded image to the dictionary\n",
    "                data[\"image\"] = encoded_image\n",
    "                \n",
    "                # Remove the old image from the PotholeQueue directory\n",
    "                #os.remove(image_path)\n",
    "                \n",
    "                # Add the dictionary to the list of parsed data\n",
    "                data_list.append(data)\n",
    "\n",
    "            else:\n",
    "                print(f\"Invalid filename format for file {filename}.\")\n",
    "        else:\n",
    "            print(f\"File {filename} is not a supported image file type.\")\n",
    "    \n",
    "    # Return the list of parsed data as a JSON string\n",
    "    return json.dumps(data_list)\n",
    "        \n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "@webapi(\"/app1/processfile\")\n",
    "def processfile(request, **kwargs):\n",
    "    DESTDIR = os.path.join(\"..\", \"dynamic\")\n",
    "    filename = uploadfile(request, **kwargs)\n",
    "    image_file = os.path.join(DESTDIR, filename)\n",
    "    VGG = os.path.join('app1', 'Models/VGG.h5')\n",
    "    output_path = run_inference(image_file, VGG)\n",
    "    image = Image.open(output_path)\n",
    "    # Apply a blue tint to the image\n",
    "    blue_image = image.copy()\n",
    "\n",
    "    # Save the modified image to a BytesIO object\n",
    "    buffer = io.BytesIO()\n",
    "    blue_image.save(buffer, format='JPEG')\n",
    "    # Encode the image as a base64 string\n",
    "    img_str = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    # Return the modified image as a JSON response\n",
    "    return JsonResponse({'image_data': img_str})\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
